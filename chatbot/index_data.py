import json
import os
import chromadb
from google import genai
from dotenv import load_dotenv

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(parent_dir, 'backend', '.env')
load_dotenv(dotenv_path=dotenv_path)

# C·∫•u h√¨nh
API_KEY = os.getenv("GEMINI_API_KEY")
EMBEDDING_MODEL = 'text-embedding-004'
CHROMA_PATH = "chroma_db"
DATA_FILE = os.path.join(os.path.dirname(__file__), 'model', 'data_chunks.json')

def get_embeddings(texts, client):
    """S·ª≠ d·ª•ng Gemini API ƒë·ªÉ l·∫•y vector cho c√°c ƒëo·∫°n vƒÉn b·∫£n"""
    embeddings = []
    print(f"B·∫Øt ƒë·∫ßu vector h√≥a {len(texts)} ƒëo·∫°n vƒÉn b·∫£n...")

    for i, text in enumerate(texts):
        try:
            # G·ªçi API cho t·ª´ng ƒëo·∫°n vƒÉn b·∫£n
            response = client.models.embed_content(
                model=EMBEDDING_MODEL,
                contents=[text],
            )

            # L·∫•y embedding t·ª´ response
            if hasattr(response, 'embedding'):
                embeddings.append(response.embedding)
            elif hasattr(response, 'values') and len(response.values) > 0:
                embeddings.append(response.values[0])
            else:
                print(f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y embedding cho ƒëo·∫°n {i}")
                embeddings.append([0.0] * 768)  # Vector m·∫∑c ƒë·ªãnh

            if (i + 1) % 5 == 0:
                print(f"  ƒê√£ x·ª≠ l√Ω {i + 1}/{len(texts)} ƒëo·∫°n...")

        except Exception as e:
            print(f"L·ªói khi vector h√≥a ƒëo·∫°n {i}: {e}")
            embeddings.append([0.0] * 768)  # Vector m·∫∑c ƒë·ªãnh n·∫øu l·ªói

    return embeddings

def create_vector_store():
    if not API_KEY:
        print("L·ªói: GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. Vui l√≤ng ki·ªÉm tra file .env")
        return

    try:
        client = genai.Client(api_key=API_KEY)
        print("‚úì K·∫øt n·ªëi Gemini API th√†nh c√¥ng")
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Gemini Client: {e}")
        return

    # 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ file chunks
    try:
        with open(DATA_FILE, 'r', encoding="utf-8") as f:
            data = json.load(f)
        print(f"‚úì ƒê√£ ƒë·ªçc {len(data)} chunks t·ª´ file d·ªØ li·ªáu")
    except FileNotFoundError:
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {DATA_FILE}")
        print("T·∫°o file data_chunks.json m·∫´u...")

        # T·∫°o d·ªØ li·ªáu m·∫´u n·∫øu ch∆∞a c√≥
        sample_data = [
            {
                "id": "chunk_1",
                "text": "H·ªá th·ªëng Qu·∫£n l√Ω Minh ch·ª©ng l√† m·ªôt n·ªÅn t·∫£ng s·ªë h√≥a gi√∫p c√°c c∆° s·ªü gi√°o d·ª•c ƒë·∫°i h·ªçc qu·∫£n l√Ω, l∆∞u tr·ªØ v√† truy xu·∫•t c√°c minh ch·ª©ng ph·ª•c v·ª• c√¥ng t√°c ki·ªÉm ƒë·ªãnh ch·∫•t l∆∞·ª£ng gi√°o d·ª•c.",
                "source": "Gi·ªõi thi·ªáu h·ªá th·ªëng"
            },
            {
                "id": "chunk_2",
                "text": "ƒê·ªÉ upload minh ch·ª©ng, ng∆∞·ªùi d√πng c·∫ßn: 1) ƒêƒÉng nh·∫≠p v√†o h·ªá th·ªëng, 2) Ch·ªçn m·ª•c Qu·∫£n l√Ω minh ch·ª©ng, 3) Nh·∫•n n√∫t T·∫°o m·ªõi, 4) ƒêi·ªÅn th√¥ng tin v√† upload file ƒë√≠nh k√®m.",
                "source": "H∆∞·ªõng d·∫´n upload"
            },
            {
                "id": "chunk_3",
                "text": "H·ªá th·ªëng h·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng file: PDF, Word (DOC, DOCX), Excel (XLS, XLSX), PowerPoint (PPT, PPTX), ·∫£nh (JPG, PNG) v√† file vƒÉn b·∫£n (TXT). Dung l∆∞·ª£ng t·ªëi ƒëa m·ªói file l√† 50MB.",
                "source": "ƒê·ªãnh d·∫°ng file h·ªó tr·ª£"
            },
            {
                "id": "chunk_4",
                "text": "C√≥ 4 vai tr√≤ ch√≠nh trong h·ªá th·ªëng: Admin (qu·∫£n tr·ªã to√†n h·ªá th·ªëng), Manager (qu·∫£n l√Ω c·∫•p ph√≤ng ban), TDG (th√†nh vi√™n t·ª± ƒë√°nh gi√°), v√† Expert (chuy√™n gia ƒë√°nh gi√°).",
                "source": "Ph√¢n quy·ªÅn ng∆∞·ªùi d√πng"
            }
        ]

        os.makedirs(os.path.dirname(DATA_FILE), exist_ok=True)
        with open(DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, ensure_ascii=False, indent=2)

        data = sample_data
        print(f"‚úì ƒê√£ t·∫°o file m·∫´u v·ªõi {len(data)} chunks")

    texts = [item['text'] for item in data]
    ids = [item['id'] for item in data]
    metadatas = [{'source': item['source']} for item in data]

    # 2. L·∫•y Embeddings
    print("\n=== B·∫Øt ƒë·∫ßu t·∫°o embeddings ===")
    embeddings = get_embeddings(texts, client)

    if not embeddings:
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o embeddings")
        return

    print(f"‚úì ƒê√£ t·∫°o {len(embeddings)} embeddings")

    # 3. L∆∞u tr·ªØ v√†o ChromaDB
    print("\n=== L∆∞u v√†o ChromaDB ===")
    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)

    # X√≥a collection c≈© n·∫øu t·ªìn t·∫°i
    try:
        chroma_client.delete_collection(name="chatbot_knowledge")
        print("‚úì ƒê√£ x√≥a collection c≈©")
    except Exception:
        print("‚úì Kh√¥ng c√≥ collection c≈©")

    # T·∫°o collection m·ªõi
    collection = chroma_client.get_or_create_collection(
        name="chatbot_knowledge",
        metadata={"hnsw:space": "cosine"}
    )
    print("‚úì ƒê√£ t·∫°o collection m·ªõi")

    # Th√™m d·ªØ li·ªáu v√†o ChromaDB
    try:
        collection.add(
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )
        print(f"‚úì ƒê√£ l∆∞u {collection.count()} documents v√†o ChromaDB")
    except Exception as e:
        print(f"L·ªói khi l∆∞u v√†o ChromaDB: {e}")
        return

    print(f"\n‚úÖ HO√ÄN TH√ÄNH! ƒê√£ vector h√≥a v√† l∆∞u tr·ªØ {collection.count()} documents")
    print(f"üìÅ D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u t·∫°i: {os.path.abspath(CHROMA_PATH)}")

    # Ki·ªÉm tra
    print("\n=== Ki·ªÉm tra k·∫øt qu·∫£ ===")
    test_query = "upload minh ch·ª©ng"
    try:
        test_embedding = client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=test_query
        )

        if hasattr(test_embedding, 'embedding'):
            query_vec = test_embedding.embedding
        else:
            query_vec = test_embedding.values[0]

        results = collection.query(
            query_embeddings=[query_vec],
            n_results=2
        )

        print(f"Test query: '{test_query}'")
        print("K·∫øt qu·∫£ t√¨m ki·∫øm:")
        for i, doc in enumerate(results['documents'][0]):
            print(f"  {i+1}. {doc[:100]}...")

    except Exception as e:
        print(f"L·ªói khi test: {e}")

if __name__ == "__main__":
    create_vector_store()