import json
import os
import chromadb
from google import genai
from dotenv import load_dotenv

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(parent_dir, 'backend', '.env')
load_dotenv(dotenv_path=dotenv_path)

# C·∫•u h√¨nh
API_KEY = os.getenv("GEMINI_API_KEY")
EMBEDDING_MODEL = 'text-embedding-004'
CHROMA_PATH = "chroma_db"
DATA_FILE = os.path.join(os.path.dirname(__file__), 'model', 'data_chunks.json')

def get_embeddings(texts):
    """S·ª≠ d·ª•ng Gemini API ƒë·ªÉ l·∫•y vector cho c√°c ƒëo·∫°n vƒÉn b·∫£n theo batch."""
    try:
        # API h·ªó tr·ª£ batching, n√™n ta c√≥ th·ªÉ g·ª≠i c·∫£ list
        response = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=texts,
            task_type="RETRIEVAL_DOCUMENT"
        )
        return response['embedding']
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi vector h√≥a batch: {e}")
        # N·∫øu batch fail, th·ª≠ l·∫°i t·ª´ng c√°i m·ªôt
        print("Th·ª≠ l·∫°i t·ª´ng vƒÉn b·∫£n m·ªôt...")
        embeddings = []
        for text in texts:
            try:
                response = genai.embed_content(
                    model=EMBEDDING_MODEL,
                    content=text,
                    task_type="RETRIEVAL_DOCUMENT"
                )
                embeddings.append(response['embedding'])
            except Exception as e_single:
                print(f"L·ªói khi vector h√≥a vƒÉn b·∫£n: {e_single}. S·ª≠ d·ª•ng vector 0.")
                embeddings.append([0.0] * 768) # Vector m·∫∑c ƒë·ªãnh
        return embeddings

def create_vector_store():
    if not API_KEY:
        print("L·ªói: GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p. Vui l√≤ng ki·ªÉm tra file .env")
        return

    genai.configure(api_key=API_KEY)
    print("‚úì C·∫•u h√¨nh Gemini API th√†nh c√¥ng")

    # 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ file chunks
    try:
        with open(DATA_FILE, 'r', encoding="utf-8") as f:
            data = json.load(f)
        print(f"‚úì ƒê√£ ƒë·ªçc {len(data)} chunks t·ª´ file d·ªØ li·ªáu")
    except FileNotFoundError:
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {DATA_FILE}")
        print("T·∫°o file data_chunks.json m·∫´u...")

        # T·∫°o d·ªØ li·ªáu m·∫´u n·∫øu ch∆∞a c√≥
        sample_data = [
            {
                "id": "chunk_1",
                "text": "H·ªá th·ªëng Qu·∫£n l√Ω Minh ch·ª©ng l√† m·ªôt n·ªÅn t·∫£ng s·ªë h√≥a gi√∫p c√°c c∆° s·ªü gi√°o d·ª•c ƒë·∫°i h·ªçc qu·∫£n l√Ω, l∆∞u tr·ªØ v√† truy xu·∫•t c√°c minh ch·ª©ng ph·ª•c v·ª• c√¥ng t√°c ki·ªÉm ƒë·ªãnh ch·∫•t l∆∞·ª£ng gi√°o d·ª•c.",
                "source": "Gi·ªõi thi·ªáu h·ªá th·ªëng"
            },
            {
                "id": "chunk_2",
                "text": "ƒê·ªÉ upload minh ch·ª©ng, ng∆∞·ªùi d√πng c·∫ßn: 1) ƒêƒÉng nh·∫≠p v√†o h·ªá th·ªëng, 2) Ch·ªçn m·ª•c Qu·∫£n l√Ω minh ch·ª©ng, 3) Nh·∫•n n√∫t T·∫°o m·ªõi, 4) ƒêi·ªÅn th√¥ng tin v√† upload file ƒë√≠nh k√®m.",
                "source": "H∆∞·ªõng d·∫´n upload"
            }
        ]

        os.makedirs(os.path.dirname(DATA_FILE), exist_ok=True)
        with open(DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, ensure_ascii=False, indent=2)

        data = sample_data
        print(f"‚úì ƒê√£ t·∫°o file m·∫´u v·ªõi {len(data)} chunks")

    texts = [item['text'] for item in data]
    ids = [str(item.get('id', f'chunk_{i}')) for i, item in enumerate(data)]
    metadatas = [{'source': item['source']} for item in data]

    # 2. L·∫•y Embeddings
    print("\n=== B·∫Øt ƒë·∫ßu t·∫°o embeddings ===")
    embeddings = get_embeddings(texts)

    if not embeddings or len(embeddings) != len(texts):
        print("L·ªói: Kh√¥ng th·ªÉ t·∫°o embeddings cho t·∫•t c·∫£ c√°c vƒÉn b·∫£n.")
        return

    print(f"‚úì ƒê√£ t·∫°o {len(embeddings)} embeddings")

    # 3. L∆∞u tr·ªØ v√†o ChromaDB
    print("\n=== L∆∞u v√†o ChromaDB ===")
    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)

    # X√≥a collection c≈© n·∫øu t·ªìn t·∫°i
    try:
        chroma_client.delete_collection(name="chatbot_knowledge")
        print("‚úì ƒê√£ x√≥a collection c≈©")
    except Exception:
        print("‚úì Kh√¥ng c√≥ collection c≈©")

    # T·∫°o collection m·ªõi
    collection = chroma_client.get_or_create_collection(
        name="chatbot_knowledge",
        metadata={"hnsw:space": "cosine"}
    )
    print("‚úì ƒê√£ t·∫°o collection m·ªõi")

    # Th√™m d·ªØ li·ªáu v√†o ChromaDB
    try:
        collection.add(
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )
        print(f"‚úì ƒê√£ l∆∞u {collection.count()} documents v√†o ChromaDB")
    except Exception as e:
        print(f"L·ªói khi l∆∞u v√†o ChromaDB: {e}")
        return

    print(f"\n‚úÖ HO√ÄN TH√ÄNH! ƒê√£ vector h√≥a v√† l∆∞u tr·ªØ {collection.count()} documents")
    print(f"üìÅ D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u t·∫°i: {os.path.abspath(CHROMA_PATH)}")

    # Ki·ªÉm tra
    print("\n=== Ki·ªÉm tra k·∫øt qu·∫£ ===")
    test_query = "upload minh ch·ª©ng"
    try:
        response = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=test_query,
            task_type="RETRIEVAL_QUERY"
        )
        query_vec = response['embedding']

        results = collection.query(
            query_embeddings=[query_vec],
            n_results=2
        )

        print(f"Test query: '{test_query}'")
        print("K·∫øt qu·∫£ t√¨m ki·∫øm:")
        for i, doc in enumerate(results['documents'][0]):
            print(f"  {i+1}. {doc[:100]}...")

    except Exception as e:
        print(f"L·ªói khi test: {e}")

if __name__ == "__main__":
    create_vector_store()