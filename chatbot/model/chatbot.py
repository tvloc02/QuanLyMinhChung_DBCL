import json
import os
import logging
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv
from google import genai
from google.genai import types
from google.genai.errors import APIError
from datetime import datetime
import re
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(parent_dir, '.env')
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path=dotenv_path)
else:
    logger.warning(f"‚ö†Ô∏è .env file not found at {dotenv_path}")

class ChatBot:
    def __init__(self, data_file=None):
        """Initialize ChatBot with training data and Gemini API"""

        # Determine correct path to training data
        if data_file is None:
            # Try multiple possible locations
            possible_paths = [
                # Current directory
                os.path.join(os.getcwd(), "training_data.json"),
                os.path.join(os.getcwd(), "model", "training_data.json"),
                # Parent directory
                os.path.join(os.path.dirname(__file__), "training_data.json"),
                os.path.join(os.path.dirname(__file__), "model", "training_data.json"),
                # Project root
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "training_data.json"),
                # With enhanced name
                os.path.join(os.getcwd(), "training_data_enhanced.json"),
                os.path.join(os.path.dirname(__file__), "training_data_enhanced.json"),
            ]

            data_file = None
            for path in possible_paths:
                if os.path.exists(path):
                    data_file = path
                    logger.info(f"‚úÖ Found training data at: {path}")
                    break

            if not data_file:
                logger.error(f"‚ùå Training data file not found in any of these locations:")
                for path in possible_paths:
                    logger.error(f"   - {path}")
                raise FileNotFoundError("training_data.json not found")

        # Load training data
        self.training_data = self._load_training_data(data_file)
        self.conversation_context = []
        self.data_file_path = data_file

        # Initialize Gemini Client
        try:
            api_key = os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("‚ùå GEMINI_API_KEY environment variable not set")

            self.client = genai.Client(api_key=api_key)
            self.model = "gemini-2.5-flash"

            self.safety_settings = [
                types.SafetySetting(
                    category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
                    threshold=types.HarmBlockThreshold.BLOCK_NONE,
                ),
                types.SafetySetting(
                    category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                    threshold=types.HarmBlockThreshold.BLOCK_NONE,
                ),
            ]

            logger.info("‚úÖ ChatBot initialized successfully with Gemini API")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Gemini Client: {e}")
            self.client = None
            raise

    def _load_training_data(self, data_file: str) -> List[Dict]:
        """Load training data from JSON file with multiple fallback options"""

        logger.info(f"üìÇ Attempting to load training data from: {data_file}")

        try:
            # Check if file exists
            if not os.path.exists(data_file):
                logger.error(f"‚ùå File does not exist: {data_file}")
                logger.info(f"üìÇ Current working directory: {os.getcwd()}")
                logger.info(f"üìÇ Script directory: {os.path.dirname(__file__)}")
                raise FileNotFoundError(f"Training data file not found: {data_file}")

            with open(data_file, encoding="utf-8") as f:
                data = json.load(f)

                # Validate data structure
                if not isinstance(data, list):
                    logger.error(f"‚ùå Training data is not a list, it's a {type(data)}")
                    return []

                logger.info(f"‚úÖ Loaded {len(data)} training data items from {data_file}")

                # Log sample of loaded data
                if data:
                    logger.info(f"üìù Sample Q&A:")
                    logger.info(f"   Q: {data[0].get('question', 'N/A')[:60]}")
                    logger.info(f"   Category: {data[0].get('category', 'N/A')}")

                return data

        except FileNotFoundError as e:
            logger.error(f"‚ùå FileNotFoundError: {e}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON parsing error: {e}")
            logger.error(f"   Make sure the JSON file is valid")
            return []
        except Exception as e:
            logger.error(f"‚ùå Unexpected error loading training data: {e}")
            return []

    def _find_relevant_qa(self, message: str, top_k: int = 3) -> List[Dict]:
        """Find relevant Q&A from training data using keyword matching"""

        if not self.training_data:
            logger.warning("‚ö†Ô∏è No training data available")
            return []

        message_lower = message.lower()
        scored_items = []

        for item in self.training_data:
            score = 0

            # Check keywords
            if 'keywords' in item:
                keywords = item['keywords']
                if isinstance(keywords, list):
                    for keyword in keywords:
                        if keyword.lower() in message_lower:
                            score += 2

            # Check question
            if 'question' in item:
                question_words = set(item['question'].lower().split())
                message_words = set(message_lower.split())
                common_words = question_words & message_words
                score += len(common_words)

            # Check category for partial match
            if 'category' in item and score > 0:
                score += 0.5

            if score > 0:
                scored_items.append((score, item))

        # Sort by score and return top K
        scored_items.sort(key=lambda x: x[0], reverse=True)
        result = [item for _, item in scored_items[:top_k]]

        logger.debug(f"üîç Found {len(result)} relevant Q&As for: {message[:50]}")
        return result

    def _build_system_prompt(self) -> str:
        """Build system prompt with training data"""

        system_prompt = (
            "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh, th√¢n thi·ªán, chuy√™n t∆∞ v·∫•n v·ªÅ "
            "**H·ªá th·ªëng Qu·∫£n l√Ω Minh ch·ª©ng (Evidence Management System)** t·∫°i CMC. "
            "\n\nNhi·ªám v·ª• ch√≠nh c·ªßa b·∫°n:\n"
            "1. Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ h·ªá th·ªëng d·ª±a tr√™n ki·∫øn th·ª©c ƒë∆∞·ª£c cung c·∫•p\n"
            "2. H∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng s·ª≠ d·ª•ng c√°c ch·ª©c nƒÉng\n"
            "3. H·ªó tr·ª£ x·ª≠ l√Ω s·ª± c·ªë\n"
            "4. Cung c·∫•p th√¥ng tin v·ªÅ quy tr√¨nh v√† ph√¢n quy·ªÅn\n"
            "\n**H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:**\n"
            "- N·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn h·ªá th·ªëng, h√£y tr·∫£ l·ªùi chi ti·∫øt\n"
            "- N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan, h√£y n√≥i: 'Xin l·ªói, t√¥i ch·ªâ c√≥ th·ªÉ h·ªó tr·ª£ c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn H·ªá th·ªëng Qu·∫£n l√Ω Minh ch·ª©ng.'\n"
            "- Lu√¥n th√¢n thi·ªán, h·ªó tr·ª£, v√† c·ª• th·ªÉ\n"
            "- ƒê·ªãnh d·∫°ng r√µ r√†ng, d·ªÖ hi·ªÉu (d√πng bullets, steps)\n"
            "\n**D·ªÆ LI·ªÜU HU·∫§N LUY·ªÜN (Q&A):**\n"
        )

        # Add training data as context
        qa_count = len(self.training_data) if self.training_data else 0

        if not self.training_data:
            system_prompt += "(‚ö†Ô∏è No training data loaded - using general knowledge)\n"
        else:
            for item in self.training_data:
                category = item.get('category', 'General')
                question = item.get('question', '')
                answer = item.get('answer', '')
                keywords = ', '.join(item.get('keywords', []))

                system_prompt += f"\n[{category}]\n"
                system_prompt += f"Q: {question}\n"
                system_prompt += f"A: {answer}\n"
                if keywords:
                    system_prompt += f"Keywords: {keywords}\n"

        logger.info(f"‚úÖ System prompt built with {qa_count} Q&As")
        return system_prompt

    def get_reply(self, message: str) -> str:
        """Get AI reply for user message"""

        if not self.client:
            logger.error("‚ùå Gemini client not initialized")
            return "D·ªãch v·ª• AI ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ki·ªÉm tra API Key."

        try:
            # Validate input
            message = message.strip()
            if not message:
                return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n."

            if len(message) > 1000:
                return "C√¢u h·ªèi qu√° d√†i. Vui l√≤ng r√∫t g·ªçn c√¢u h·ªèi c·ªßa b·∫°n."

            # Find relevant training data
            relevant_qa = self._find_relevant_qa(message, top_k=5)

            system_prompt = self._build_system_prompt()

            # Build context for conversation
            context = "\n\n**RELEVANT TRAINING DATA FOR THIS QUESTION:**\n"
            if relevant_qa:
                for qa in relevant_qa:
                    context += f"Q: {qa.get('question', '')}\n"
                    context += f"A: {qa.get('answer', '')}\n\n"
            else:
                context = "\n\n(No directly relevant training data found - use general knowledge about the system)"

            full_prompt = f"{system_prompt}{context}\n\nUser Question: {message}"

            logger.info(f"üì® Processing message: {message[:50]}...")

            # Call Gemini API
            response = self.client.models.generate_content(
                model=self.model,
                contents=full_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=300,
                    safety_settings=self.safety_settings
                )
            )

            reply = response.text.strip()

            # Check for out-of-scope responses
            unrelated_phrases = [
                "xin l·ªói, t√¥i ch·ªâ c√≥ th·ªÉ h·ªó tr·ª£",
                "kh√¥ng li√™n quan",
                "ngo√†i ph·∫°m vi"
            ]

            is_unrelated = any(phrase in reply.lower() for phrase in unrelated_phrases)
            if is_unrelated and len(relevant_qa) == 0:
                return "Xin l·ªói, c√¢u h·ªèi n√†y n·∫±m ngo√†i ph·∫°m vi h·ªó tr·ª£ c·ªßa t√¥i. T√¥i ch·ªâ c√≥ th·ªÉ h·ªó tr·ª£ v·ªÅ H·ªá th·ªëng Qu·∫£n l√Ω Minh ch·ª©ng. Vui l√≤ng ƒë∆∞a ra c√¢u h·ªèi kh√°c ho·∫∑c li√™n h·ªá team support."

            # Add to conversation context
            self.conversation_context.append({
                "timestamp": datetime.now().isoformat(),
                "user_message": message,
                "bot_reply": reply,
                "relevant_topics": [qa.get('category', 'Unknown') for qa in relevant_qa]
            })

            # Keep only last 10 messages
            if len(self.conversation_context) > 10:
                self.conversation_context = self.conversation_context[-10:]

            logger.info(f"‚úÖ Reply generated successfully")
            return reply

        except APIError as e:
            logger.error(f"‚ùå Gemini API error: {e}")
            return "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i sau."

        except Exception as e:
            logger.error(f"‚ùå Unexpected error in get_reply: {e}")
            return "Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá support."

    def get_contextual_followup(self, last_reply: str, last_message: str = "") -> List[str]:
        """Generate contextual follow-up questions"""

        if not self.client:
            logger.warning("‚ö†Ô∏è Gemini client not initialized, skipping follow-up generation")
            return []

        try:
            # Check if response is about out-of-scope
            if "xin l·ªói, c√¢u h·ªèi n√†y n·∫±m ngo√†i ph·∫°m vi" in last_reply.lower():
                return []

            prompt = (
                f"D·ª±a tr√™n c√¢u tr·∫£ l·ªùi cu·ªëi c√πng n√†y t·ª´ tr·ª£ l√Ω AI:\n'{last_reply}'\n\n"
                "H√£y ƒë·ªÅ xu·∫•t 3 c√¢u h·ªèi ti·∫øp theo ng·∫Øn g·ªçn (d∆∞·ªõi 10 t·ª´) m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ h·ªèi ti·∫øp.\n\n"
                "Ch·ªâ tr·∫£ l·ªùi b·∫±ng 3 c√¢u h·ªèi, m·ªói c√¢u n·∫±m tr√™n m·ªôt d√≤ng, kh√¥ng c√≥ s·ªë th·ª© t·ª±."
            )

            logger.info("üí≠ Generating follow-up questions...")

            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.5,
                    max_output_tokens=100,
                    safety_settings=self.safety_settings
                )
            )

            suggestions_text = response.text.strip()
            suggestions = [
                s.strip()
                for s in suggestions_text.split('\n')
                if s.strip() and len(s.strip()) > 5
            ]

            # Clean up suggestions
            cleaned_suggestions = []
            for s in suggestions[:3]:
                cleaned = re.sub(r'^[\d\.\)\-\s]+', '', s).strip()
                if cleaned:
                    cleaned_suggestions.append(cleaned)

            logger.info(f"‚úÖ Generated {len(cleaned_suggestions)} follow-up questions")
            return cleaned_suggestions[:3]

        except APIError as e:
            logger.error(f"‚ùå API error generating follow-up: {e}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Error in get_contextual_followup: {e}")
            return []

    def search_qa(self, query: str) -> List[Dict]:
        """Search through training data for relevant Q&A"""

        relevant = self._find_relevant_qa(query, top_k=5)
        logger.info(f"üîç Search for '{query}' found {len(relevant)} results")
        return relevant

    def get_categories(self) -> List[str]:
        """Get all available categories"""

        categories = set()
        for item in self.training_data:
            if 'category' in item:
                categories.add(item['category'])

        result = sorted(list(categories))
        logger.info(f"üìö Retrieved {len(result)} categories")
        return result

    def get_qa_by_category(self, category: str) -> List[Dict]:
        """Get all Q&A items for a specific category"""

        result = [
            item for item in self.training_data
            if item.get('category', '').lower() == category.lower()
        ]
        logger.info(f"üìñ Retrieved {len(result)} items for category '{category}'")
        return result

    def get_all_questions(self) -> List[str]:
        """Get all available questions"""

        return [item.get('question', '') for item in self.training_data if 'question' in item]

    def validate_message(self, message: str) -> Tuple[bool, Optional[str]]:
        """Validate user message"""

        if not message:
            return False, "Vui l√≤ng nh·∫≠p m·ªôt c√¢u h·ªèi."

        if len(message.strip()) < 3:
            return False, "C√¢u h·ªèi qu√° ng·∫Øn. Vui l√≤ng nh·∫≠p chi ti·∫øt h∆°n."

        if len(message) > 1000:
            return False, "C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 1000 k√Ω t·ª±)."

        # Check for spam
        if re.search(r'(.)\1{9,}', message):
            return False, "Tin nh·∫Øn c√≥ d·∫•u hi·ªáu spam. Vui l√≤ng nh·∫≠p l·∫°i."

        return True, None

    def clear_context(self):
        """Clear conversation context"""
        self.conversation_context = []
        logger.info("üóëÔ∏è Conversation context cleared")

    def get_conversation_context(self) -> List[Dict]:
        """Get current conversation context"""
        return self.conversation_context

    def get_status(self) -> Dict:
        """Get chatbot status"""
        return {
            "initialized": self.client is not None,
            "training_data_loaded": len(self.training_data),
            "categories": len(self.get_categories()),
            "data_file": self.data_file_path,
            "timestamp": datetime.now().isoformat()
        }